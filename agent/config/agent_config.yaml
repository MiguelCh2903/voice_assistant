agent:
  ros__parameters:
    # LLM Configuration
    llm:
      # Provider: "openai" or "groq"
      provider: "groq"
      
      # Model name (provider-specific)
      # OpenAI models: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
      # Groq models: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
      model: "gpt-oss-120b"
      
      # LLM parameters
      temperature: 0.7
      max_tokens: 500
      streaming: true
      timeout: 10.0
      
    # Conversation Management
    conversation:
      # Maximum number of messages to keep in history (10 pairs = 20 messages)
      max_history_messages: 10
      # Conversation ID prefix
      id_prefix: "cami_conv_"
      
    # Streaming Configuration
    streaming:
      # Accumulate tokens until end of sentence
      accumulate_sentences: true
      # Sentence delimiters (regex pattern)
      sentence_delimiters: "[.?!]"
      # Common abbreviations in Spanish to avoid premature sentence breaks
      abbreviations:
        - "Dr."
        - "Dra."
        - "Sr."
        - "Sra."
        - "Ing."
        - "Lic."
        - "Prof."
        - "etc."
        - "p.ej."
        - "aprox."
        
    # Prompt Configuration
    prompt:
      # Path to system instructions file (relative to package share)
      instructions_file: "cami_host_instructions.txt"
      
    # Response Metadata
    response:
      # Default intent for conversational responses
      default_intent: "chat"
      # Default confidence score
      default_confidence: 0.95
